{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Here, we can test our saved model 'VSmegaClassifier,' which we trained and tested in the previous step.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3XNfjYVq7Qt_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGfNN-tpLQJW",
        "outputId": "6571bbe4-eaf7-4689-a67a-010a624082ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieving folder contents\n",
            "Processing file 1QyyqUiEHAeLKWj92txIrUsGnF8rW1Jab config.json\n",
            "Processing file 1-6kU8-83ccNRhCOnaM4e5i04LJrO4n_S merges.txt\n",
            "Processing file 1-6dAG_xvu7gU-xWcbHd7_Z5DPGyF0GkZ model.safetensors\n",
            "Processing file 1-QlRQd6ieeKqVg9S3Rul0eTCEJZ9O0zL special_tokens_map.json\n",
            "Processing file 1-NHncU_VSqdTf4GQ7J1mRO6tKdLIFq9r tokenizer_config.json\n",
            "Processing file 1-HETGNrwd5OaHtam36vtqhEjVlPs6y_M tokenizer.json\n",
            "Processing file 1-E4hPPgrDKuxxQd6B_LOb5DKgFX2uki2 vocab.json\n",
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1QyyqUiEHAeLKWj92txIrUsGnF8rW1Jab\n",
            "To: /content/VSmegaClassifier/config.json\n",
            "100% 691/691 [00:00<00:00, 3.22MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-6kU8-83ccNRhCOnaM4e5i04LJrO4n_S\n",
            "To: /content/VSmegaClassifier/merges.txt\n",
            "100% 456k/456k [00:00<00:00, 98.4MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1-6dAG_xvu7gU-xWcbHd7_Z5DPGyF0GkZ\n",
            "From (redirected): https://drive.google.com/uc?id=1-6dAG_xvu7gU-xWcbHd7_Z5DPGyF0GkZ&confirm=t&uuid=5e96da7d-1abb-4887-82d7-b9cabe1b672d\n",
            "To: /content/VSmegaClassifier/model.safetensors\n",
            "100% 328M/328M [00:01<00:00, 192MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-QlRQd6ieeKqVg9S3Rul0eTCEJZ9O0zL\n",
            "To: /content/VSmegaClassifier/special_tokens_map.json\n",
            "100% 280/280 [00:00<00:00, 1.28MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-NHncU_VSqdTf4GQ7J1mRO6tKdLIFq9r\n",
            "To: /content/VSmegaClassifier/tokenizer_config.json\n",
            "100% 1.22k/1.22k [00:00<00:00, 5.83MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-HETGNrwd5OaHtam36vtqhEjVlPs6y_M\n",
            "To: /content/VSmegaClassifier/tokenizer.json\n",
            "100% 2.11M/2.11M [00:00<00:00, 168MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1-E4hPPgrDKuxxQd6B_LOb5DKgFX2uki2\n",
            "To: /content/VSmegaClassifier/vocab.json\n",
            "100% 798k/798k [00:00<00:00, 115MB/s]\n",
            "Download completed\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "!gdown --folder 'https://drive.google.com/drive/folders/1nKtZ4k7ApjwdELhsCf9vG-vHcbj7QPb6'\n",
        "def get_model_and_tokenizer():\n",
        "    tokenizer = AutoTokenizer.from_pretrained('VSmegaClassifier')\n",
        "    model = AutoModelForSequenceClassification.from_pretrained('VSmegaClassifier')\n",
        "    return model, tokenizer\n",
        "\n",
        "saved_model, saved_tokenizer = get_model_and_tokenizer()\n",
        "\n",
        "model_pipeline = pipeline('text-classification', model=saved_model, tokenizer=saved_tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_text = \"I like to use the Amazon reviews when purchasing books, especially alert for dissenting perceptions about highly rated items, which usually diseases me from a selection. So I offer this review that seriously questions the popularity of this work\"\n",
        "result = model_pipeline(example_text)\n",
        "\n",
        "\n",
        "\n",
        "# Determine sentiment based on the label\n",
        "if result[0]['label'] == 'LABEL_0':\n",
        "    sentiment = 'negative'\n",
        "elif result[0]['label'] == 'LABEL_1':\n",
        "    sentiment = 'positive'\n",
        "print(f\"Sentiment: {sentiment}\")\n",
        "\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJOGsv3gLg-M",
        "outputId": "b7424ccf-cf16-43ef-f1be-4c35f36c7893"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentiment: negative\n",
            "[{'label': 'LABEL_0', 'score': 0.9990158081054688}]\n"
          ]
        }
      ]
    }
  ]
}